{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modeling part of NLP > a lot of feature engineering (ex: w/ tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unicodedata > decode to uni\n",
    "json > webscrape or process\n",
    "nltk > tokenize (remove special character, split inidividual word)# each word assigned an numeric value\n",
    "nltk.corpus rm stopword\n",
    "\n",
    "normalize > \n",
    "\n",
    "stem > simply chop off \"unnecessary\" words \n",
    "lemmatize > use linguistic rules to determine how to process a word\n",
    "ex: \n",
    "    bought > bot (stem) \n",
    "    bought > buy (lemmatize)\n",
    "    \n",
    "    \n",
    "df.assign(origina = df.title) # now we duplicate df.title and assign it into a new col \"original\"\n",
    "#create new col 'normalized', fill in \"normalized\" df.original using the function normalize\n",
    "df.assign(normalized = df.original.apply(normalize)) \n",
    "\n",
    "value_counts(normalized = True) # return count as % proportions\n",
    "\n",
    "if school exist a lot, very low IDF\n",
    "e.g. if we are scrapping codeup blog (w/o knowing the company name)\n",
    "then the document(blog article) containing \"codeup\" won't give us info\n",
    "log(100/(50+1))\n",
    "\n",
    "but car manufacturer shouldn't appear in document, or not much\n",
    "so say if it only appear in 1 doc/article\n",
    "> log(100/(1+1)) if we see this number means there might be something interesting \n",
    "\n",
    "IDF small means less informative (appear all over the place\n",
    "large means it might mean a lot\n",
    "\n",
    "augmented freq if the % of a particular word is skewed, we can alleviate the skew/ normalize\n",
    "\n",
    "doc = df.col.to_dict()\n",
    "check whole dictionary: doc.items()\n",
    "for key, value in doc.items() >> allow us to access key & value\n",
    "\n",
    "tf-idf = tf * idf\n",
    "high tf & high idf is the best lol\n",
    "overall it appeared a lot in our search and concentrate in a few document\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
